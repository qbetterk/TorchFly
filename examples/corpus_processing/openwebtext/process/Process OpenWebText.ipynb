{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tarfile\n",
    "import tqdm\n",
    "import ray\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-20 20:41:13,397\tWARNING services.py:597 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-02-20 20:41:13,398\tINFO resource_spec.py:216 -- Starting Ray with 34.18 GiB memory available for workers and up to 17.09 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '169.237.10.101',\n",
       " 'redis_address': '169.237.10.101:59498',\n",
       " 'object_store_address': '/tmp/ray/session_2020-02-20_20-41-13_396332_8589/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-02-20_20-41-13_396332_8589/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2020-02-20_20-41-13_396332_8589'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def extract(filename, output_path):\n",
    "    tar = tarfile.open(filename)\n",
    "    tar.extractall(path=output_path)\n",
    "    tar.close()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../download/scraped/\"\n",
    "OUTPUT_PATH = \"../temp/openwebtext_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(DATA_PATH, \"*.xz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:00<00:00, 3679.29it/s]\n",
      "100%|██████████| 213/213 [02:24<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "objects = []\n",
    "\n",
    "for count, file in enumerate(tqdm.tqdm(files)):\n",
    "    filename = file\n",
    "    output_path = os.path.join(OUTPUT_PATH, str(count))\n",
    "    \n",
    "    obj_id = extract.remote(filename, output_path)\n",
    "    objects.append(obj_id)\n",
    "    \n",
    "for i in tqdm.trange(len(files)):\n",
    "    assert ray.get(objects[i]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_url(name):\n",
    "    url = name.split(\"/\")[-1][:-4].split(\"-\")[1]\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_folders = glob.glob(os.path.join(OUTPUT_PATH, \"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def write_to_json(txt_files, output_filename, rank):\n",
    "    f_write = open(output_filename, \"w\")\n",
    "    \n",
    "    if rank == 0:\n",
    "        txt_files = tqdm.tqdm(txt_files)\n",
    "    \n",
    "    for txt_file in txt_files:\n",
    "        # get url hash\n",
    "        url = extract_url(txt_file)\n",
    "        with open(txt_file, \"r\") as f_read:\n",
    "            line = {\n",
    "                \"text\": f_read.read(),\n",
    "                \"url\": url\n",
    "            }\n",
    "            line = json.dumps(line)\n",
    "            f_write.write(line)\n",
    "            f_write.write(\"\\n\")\n",
    "\n",
    "    f_write.close()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../temp/openwebtext_json\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49406 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1895/49406 [00:00<00:02, 18948.12it/s]\n",
      "  8%|▊         | 3772/49406 [00:00<00:02, 18891.21it/s]\n",
      " 11%|█         | 5475/49406 [00:00<00:02, 18290.32it/s]\n",
      " 15%|█▍        | 7317/49406 [00:00<00:02, 18328.06it/s]\n",
      " 19%|█▊        | 9202/49406 [00:00<00:02, 18479.58it/s]\n",
      " 23%|██▎       | 11117/49406 [00:00<00:02, 18675.59it/s]\n",
      " 26%|██▋       | 13017/49406 [00:00<00:01, 18769.58it/s]\n",
      " 30%|███       | 14977/49406 [00:00<00:01, 19009.77it/s]\n",
      " 34%|███▍      | 16771/49406 [00:00<00:01, 18408.52it/s]\n",
      " 38%|███▊      | 18554/49406 [00:01<00:01, 18226.56it/s]\n",
      " 41%|████      | 20328/49406 [00:01<00:01, 17807.91it/s]\n",
      " 45%|████▍     | 22077/49406 [00:01<00:01, 17521.76it/s]\n",
      " 48%|████▊     | 23808/49406 [00:01<00:01, 17380.74it/s]\n",
      " 52%|█████▏    | 25564/49406 [00:01<00:01, 17433.38it/s]\n",
      " 55%|█████▌    | 27307/49406 [00:01<00:01, 17428.83it/s]\n",
      " 59%|█████▉    | 29043/49406 [00:01<00:01, 16683.07it/s]\n",
      " 62%|██████▏   | 30731/49406 [00:01<00:01, 16739.17it/s]\n",
      " 66%|██████▌   | 32407/49406 [00:01<00:01, 16682.16it/s]\n",
      " 69%|██████▉   | 34177/49406 [00:01<00:00, 16973.51it/s]\n",
      " 73%|███████▎  | 35877/49406 [00:02<00:01, 8970.63it/s] \n",
      " 76%|███████▌  | 37484/49406 [00:02<00:01, 10340.07it/s]\n",
      " 79%|███████▉  | 39129/49406 [00:02<00:00, 11635.58it/s]\n",
      " 82%|████████▏ | 40606/49406 [00:02<00:01, 6911.03it/s] \n",
      " 85%|████████▍ | 41940/49406 [00:03<00:00, 8079.10it/s]\n",
      " 87%|████████▋ | 43139/49406 [00:03<00:00, 8924.61it/s]\n",
      " 90%|████████▉ | 44332/49406 [00:03<00:00, 5746.41it/s]\n",
      " 92%|█████████▏| 45578/49406 [00:03<00:00, 6854.04it/s]\n",
      " 95%|█████████▍| 46838/49406 [00:04<00:00, 5016.29it/s]\n",
      " 97%|█████████▋| 48040/49406 [00:04<00:00, 6078.83it/s]\n",
      "100%|██████████| 49406/49406 [00:04<00:00, 11633.02it/s]\n"
     ]
    }
   ],
   "source": [
    "ray_objs = []\n",
    "\n",
    "for i, folder in enumerate(processed_folders):\n",
    "    txt_files = glob.glob(os.path.join(folder, \"*\"))\n",
    "    obj = write_to_json.remote(txt_files, f\"../temp/openwebtext_json/{i}.jsonl\", rank=i)\n",
    "    ray_objs.append(obj)\n",
    "    \n",
    "for i, folder in enumerate(processed_folders):\n",
    "    ray.get(ray_objs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [01:17<00:00,  2.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# f_write = open(\"train_data.jsonl\", \"w\")\n",
    "\n",
    "# for file in tqdm.tqdm(glob.glob(\"openwebtext_json/*\")):\n",
    "#     with open(file, \"r\") as f_read:\n",
    "#         for line in f_read:\n",
    "#             f_write.write(line)\n",
    "        \n",
    "# f_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/cleaned\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_NUM_CHUNKS = 213\n",
    "\n",
    "@ray.remote\n",
    "def call_command(i):\n",
    "    command = f\"python cleanup_dataset.py ../temp/openwebtext_json/{i}.jsonl ../data/cleaned/{i}.jsonl\"\n",
    "    subprocess.run(command, shell=True)\n",
    "    return 0\n",
    "\n",
    "ray_objs = []\n",
    "\n",
    "for i in range(TOTAL_NUM_CHUNKS):\n",
    "    ray_objs.append(call_command.remote(i))\n",
    "\n",
    "for i in tqdm.trange(TOTAL_NUM_CHUNKS):\n",
    "    ray.get(ray_objs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove folders\n",
    "# shutil.rmtree(\"openwebtext_json/\")\n",
    "# shutil.rmtree(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_write = open(\"data/cleaned_data.jsonl\", \"w\")\n",
    "\n",
    "for file in tqdm.tqdm(glob.glob(\"data/cleaned/*\")):\n",
    "    with open(file, \"r\") as f_read:\n",
    "        for line in f_read:\n",
    "            f_write.write(line)\n",
    "        \n",
    "f_write.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}